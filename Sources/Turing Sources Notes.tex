\documentclass{article}
\usepackage[citestyle=numeric,datamodel=../citationfields]{biblatex}
\addbibresource{../refs.bib}
\usepackage{../citationformats}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{titlesec}
\usepackage{ulem}

% \DeclareLabelname[letter]{
% 	\field{author}
% 	\field{addressee}
% 	\field{date}
% 	\field{location}
% 	\field{title}
% 	\field{note}
% }
\DeclareLabelname[movie]{
    \field{director}
    \field{producer}
}

\renewcommand{\thesection}{AMT-\Alph{section}}
\renewcommand{\thesubsection}{AMT-\Alph{section}-\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\roman{subsubsection}}

\titleclass{\subsubsubsection}{straight}[\subsubsection]
\newcounter{subsubsubsection}
\renewcommand{\thesubsubsubsection}{\thesubsubsection.\roman{subsubsubsection}}
\titleformat{\subsubsubsection}{\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\setcounter{secnumdepth}{4} % Numbers sections up to subsubsubsection
\setcounter{tocdepth}{4}    % Includes sections up to subsubsubsection in ToC

\begin{document}
	\section{Biographical and Personal Documents}
		\subsection{AMT-A-1}
			\subsubsection{Kings Report}
				\cite{amt-a-1-kings}Appears to be obituaries, potentially by Kings College Cambridge, in 1954.
				Notes Turing as not finding interest in Part I of Tripos.
				Notes his interest in formal logic and ordinal logic.
				Very little on his work in WW2.
				\begin{quotation}
					He returned to Kings in 1938. On the Outbreak of war he was invited to join the foreign Office. For his distinguished services during the war he was awarded the OBE. He then turned to the problems involved in the designand use of electronic computing machines.
				\end{quotation}
				Turing's work with the Manchester Computor is noted. 
				Notes his long distance running.
				Notes 1951 election to F.R.S.
				Notes work on theory of organic growth.
				Little said on his death.
				\begin{quotation}
					[H]e was found dead in his house at Wilmslow on Cheshire.
				\end{quotation}

			\subsubsection{Manchester Guardian 1957}
				Published in Machester Guardian in 1957\cite{amt-a-1-manchester57}.
				Reports verdict on death of Alan Turing.
				Notes that death was ruled as suicide by cyanide poisoning.
				Evidence comes from bubbling contents of a pan and the smell of almonds.
				Notes that Turing's brother John was hmslef alive. 
				Turing's brother seemed to testify that Alan was in good health and had no financial difficulty.

			\subsubsection{Manchester Guardian Obituary (1954/06/10)}
			
			\subsubsection{Manchester Guardian Appreciation by M.H.A.N.}
				1954/06/11.
				MHAN could easily be Maxwell Herman Alexander Newman, who knew Turing.
				Newman did not work with Turing on Enigma but did work at Bletchley Park at the same time.
				
		\subsection{}
		\subsection{}
		Two identical publications, from May and November of 1972, 18 years after Turing's death and 27 after WW2 ended.

		Details Turing's and John von Neumann's relationship prior to WW2.

	\section{Publications, Lectures, and Talks}
		\subsection{}
		\subsection{}
		\subsection{}
		\subsection{}
		\subsection{Can Digital Computers Think? (1951)}
			Appears to be a transcript or prepard oration of a radio broadcast by Turing May 15, 1951\cite{amt-b-5}.

			\subsubsection{Page 1}
			Attempts to explain different perspectives of whether machines are effectively brains.

			Towards start, quotes Ada Lovelace.
			
			\begin{quote}
				Their outlook was well summed up by Lady Lovelace over a hundred years ago, speaking of Babbage's Analytical Engine. 
				She said, as Hartree has already quoted, `The Analytcal Machne has no pretensions whatever whatever to orginate anything. 
				It can do whatever we know how to order it to perform.'
			\end{quote}

			\subsubsection{Page 2}
				Sets out a claim that the brain could be imitated by a machine in certain circumstances and with certain assumptions.
				\begin{quote}
					If now some particular machine can be described as a brain we have only to programme our digital computer to imitate it and it will also be a brain.
				\end{quote}

			\subsubsection{Page 3}
				Makes a comment about the Indeterminacy Principle (likely refering to the Heisenberg\footnote[1]{Say his name} Uncertainty Principle) saying a computer to imitate the human brain is impossible due to some things being unpredictable by calculation.
				The Heisenberg$^1$ Uncertainty Principle refers to the inability to know precisely where a quantum particle is and what its momentum is at the same time.
				This could be in reference to the brain, in which the action potential produced by neurons is an electrical impulse, although this is in the form of Sodium and Potassium ions rather than electrons, so this is less likely.
				This could also be in reference to the computers using electricity, which is conducted through metals (in wires) in our current day.
				I'm unsure how electricity was conducted in the machines Turing worked with.
				Turing credits this argument to Sir Arthur Eddington\footnote{Wikipedia article: \url{https://en.wikipedia.org/wiki/Arthur_Eddington}}, the man who led the expedition that proved Einstein's theory of General Relativity, so he and his ideas about this may be worth looking in to. 

				Turing notes the nesessarry size of the brain-computer's storage.
				He notes it must be at least 100 times the size of the Manchester Computer unless a way for data to be shrunk were possible.
				The ``Manchester Computer'' could refer to either the Manchester Baby or the Manchester Mark 1.
				Assuming the Manchester Computer refered to is the 1948 Manchester Baby, the storage of the was 1024 bits (128 bytes, or 1 kibibit)\cite{ne-jubilee} that lasted for several hours.
				A computer with 100 times the storage (rounding up to 128 for the sake of computers' use of powers of 2) would have 131072 bits (16384 bytes), somewhere between a kilobyte and a megabyte.
				This is significantly less than the number of neurons in the human brain ($\approx$ 86 billion).

			\subsubsection{Page 4}
				Most of page 5 is dedicated to an analogy for why a computer would not require more complexity to run a more complex program.
				The analogy does not seem to make much sense and seems to go off on a tangent and leave suppositions it brought up forgotten.

				The rest of the page goes into not knowing how a machine would be programed to act like a human brain.
				The below quote (going into the next page) describes soemthing that would be best described as a minor prediction of LLMs, albeit off by about 20 years.
				\begin{quote}
					I think it is probable for instance that at the end of the century it will be possible to programme a machine to answer questions in such a way that it will be extremely difficult to guess whether the answers are being given by a man or by the machine.
				\end{quote}

			\subsubsection{Page 5}
				Turing gets into the philosophical-psychological question of free will and the question of both whether the human mind has free will and whether a computer has free will.
				Turing offers two possibile answers, one for if free will exists and one for if it does not.
				No free will means that the machine can imitate human action through a programming.
				Free will existing means the machine can come close to imitating it.
				He proposes either a roulette wheel or radium, but dismisses the idea of the necessity of truly random processes in the next paragraph.

			\subsubsection{Page 6}
				Turing comments on what boils down to ``One needs not know how something works in order to use it''.
				It gets into how one would program a machine to think.

				Turing mentions there being many ideas as to how to get a machine to think.
				He remarks that he thinks the process should bear a close resemblance to teaching.
				It should be noted that modern machine learning does not bear much legitimate resemblance to teaching. 
				To my understanding, it acts on creating mini-machines, testing them in a series of true-false quizzes and using them to make future models. 
				It bears a much closer resemblance to evolution than to teaching.

			\subsubsection{Page 6a}
				The main paragraph on this page concerns people's opposition to the possibility of the machine learning to think.
				He chocks it up to a fear of an opponent or rival.

			\subsubsection{Page 7}
				\begin{quote}
					It might for instance be said that no machine could write good English,
				\end{quote}
				That quote certainly aged.
				Turing states his belief that there is little boundary in what a machine will be able to do.
				He concludes by commenting on his hope that learning how machines think will help with understanding how we ourselves think.

	\section{Unpublished Manuscripts and Drafts}

	\section{Correspondence}
		\subsection{Letters to Mother}
			\subsubsection{}
				Unknown date of sending or reception.
				Copy received January 1954, five months before Turing's death.
				If the letter is indeed from that date, Turing would have (likely) been living just south of Manchester, currently a 3 hour train ride from London (likely more back then).
				Could have taken place while Turing was at Princeton, so between 1936 and 1938.
				Could have taken place while Turing was at Bletchley Park during WW2.
				Could have taken place while Turing lived in Hampton, London.

				Notes a "M of S" document. 
				Only lead goes to Memorandum of Sale document for property transactions.
				Could be the subject, might not.

				Notes dislike of American defnition of `classified'/`declassified'.
				I personally agree wth it.
				Turing could read German.
				I recall seeing an early draft of a paper he wrote in French\cite{amt-k-4}, so that adds intrigue.

				Turing later recalls and recommends a shop in London for buying wedding presents.
				He also notes a man named Fred who has a wife who is a landlady.
				She may be his landlady.

				He concludes his letter with a post-script about an individual named Webbs leaving from wherever Turing is.
				A lack of results about any such `Webbs' at Princeton during Turing's time there (besides a few people in the graduating class and Michael Webb who worked at Princeton and was \textit{born} in 1937) discourages my theory of the timing.
				Perhaps this was written while Turing was at Bletchley (no mention of the war, but not unplausible) or when he lived in Hampton (1945-1947).

			\subsubsection{March 15, 1937}
				Letter from Turing to mother from Princeton Graduate College.

				Mentions the recent fellowshp elections.
				Turing was a Jane Eliza Procter Visiting Fellow in his second year at Princeton.
				Includes people he hopes or wonders if will be selected as fellows (Champerowne and Champ, possibly the same person).

				Also notes a play reading society.
				Sounds fun in my personal opinion.

			\subsubsection{March 29, 1937}
				Letter from Turing to mother from Princeton Graduate College.

				Notes that Champernowne (an economist of Champernown constant\footnote{$C_{10} = 0.12345678910111213\dots$} fame) was granted the fellowship at King's.

				Relates wrting down some ideas in logc, believed in the document to be preperatory steps for hs PhD Dissertation ``Systems of logic based on ordinals''.

			\subsubsection{Handwritten Letter}
				Cannot read this presently. 
				Come back to it.

		\subsection{Letters to Max Newman}
			All letters are handwrtten (come back to them) except two copies of an unsent letter to Church.
			Turing's handwritng is \textit{very} difficult to read.

			\subsubsection{}

			\subsubsection{}
			
			\subsubsection{}
			
			\subsubsection{}
			
			\subsubsection{}
			
			\subsubsection{Draft Letter to Church}
				Half handwritten, half typed.

			\subsubsection{Other Draft to Church}

		\subsection{(Sometimes labeled \texttt{AMT-D-5}) Correspondences with I.J. ``Jack'' Good}
			01-03 appear to be the same letter to I.J. Good\footnote{Wikipedia article on I.J. Good: \url{https://en.wikipedia.org/wiki/I._J._Good}}.
			They have the same text, at least.

			All documents are to Good except the last from Good to Turing.

			\subsubsection{September 18, 1948}
				Three years before Turing's work in mathematical biology began.
				Mentions an estimate of a number of neurons, potentially in the human brain?

				Comments on his chess machine he made with one `Champ'.
				Said `Champ' is most likely D.G. Champernowne, who Turing wrote a chess algorithm with begnning in 1948.

				A metaphor or comment Good made about `thnking in analogies' is made.

				The letter is concluded with what appears to be an identity Good thought of, which Turing connects to Poisson's summation formula and contour integration.

			\subsubsection{Same as prior}
			\subsubsection{Same as prior}
			\subsubsection{July 28, 1948}
				Clarifies Turing's estimation about number of neurons to be between $3 \times 10^8$ and $3 \times 10^9$.
				This estimate is based on the weight of a mouse's brain and the mouse brain's neuron count compared to the human brain's (a simple ratio problem).

			\subsubsection{July 25, 1948 (from Good to Turing)}
				Good recalls a lecturer who estimated the human brain to have two million neurons.
				Good thought the estimate to be vastly too low, explaining the origin of the correspondence. 

				Good also asks Turing how `near' he was to getting into the Olympics. 
				The summer olympics in 1948 were held in London, England.
				Good may have been asking how close Turing was to qualifying for the Olympics, or (less likely) how close he was to getting into a stadium to watch the Olympics that summer.
				In the case of the former, Turing was memorably an avid runner.

		\subsection{Correspondence with Robin O. Gandy}
			Gandy was a doctoral student of Turing's\footnote{Wikipedia article on R.O. Gandy: \url{https://en.wikipedia.org/wiki/Robin_Gandy}}.
			Gandy's work was largely about Recursion Theory, which drew from Turing's work.
			
			All documents are dated to 1953-1954, 0-1 years before Turing's death in 1954.

			All documents are handwritten.

		\subsection{(Sometimes labeled \texttt{AMT-D-9}) Various Letters to Turing}
			\subsubsection{C.G. Darwin; November 11, 1947}
				Letter from physicist Charles Galton Darwin\footnote{Grandson of Charles Darwin. Wikipedia article: \url{https://en.wikipedia.org/wiki/Charles_Galton_Darwin}}, who was director of the National Physics Labratory at the time.
				Darwin mentions reading a recent ``signed and sent out'' paper by Turing.
				He complements the content, but criticizes the quality of the paper.

			\subsubsection{J.Z. Young; January 13, 1951}
				Handwritten letter from John Z. Young, likely the oxford zoologist\footnote{If so, his Wikipedia article: \url{https://en.wikipedia.org/wiki/John_Zachary_Young}}.
				At the time of writing, Turing was turning towards mathematical biology. 

			\subsubsection{Christopher Strachey; May 15, 1951}
				\cite{amt-d-5-iii}Regards the radio broadcast on the same day\cite{amt-b-5} about the idea of a computer brain.
				Christopher Strachey\footnote{Wikipedia: \url{https://en.wikipedia.org/wiki/Christopher_Strachey}} was a British Computer Scientist who was a pioneer in probramming language design.

				\subsubsubsection{Page 1}
					Starchey notes Turing's comment on the similarity of programing a machine to think and teaching the machine.
					He concurs with Turing's idea of teaching a machine, which has some similarity with teaching an LLM\footnote{if it were up to me, I would say that it concurs well with the LLM. LLMs are built on copying their input. In essence, they teach through exposure, like making a child read a bunch of books to teach them to write well.}.

					Starchey notes the most important difference between a machine and a human mind in his opinion is that a machine would have to be told what patterns to look for while a human has an inherent ability to notice patterns\footnote{I don't know enough about LLMs to know if they're trained to recognize new patterns}.
					He encourages the idea that a computer learning would bring it closer to thinking.

				\subsubsubsection{Page 2}
					Starchey adds on being able to use relationships learned.
					After setting aside things that just have to be memorized like language or multiplication tables (call those axioms for the time being if necessary), Starchey begins talking about machines that play games.
					He calls to mind an example of a machine that could play Nim\footnote{Wikipedia: \url{https://en.wikipedia.org/wiki/Nim}} and note down and recall any winning positions it had.
					Starchey notes that when the machine played against his non-mathmatician friend Anthony.
					He notes Anthony as finding the winning position to be any configuration of \texttt{(n,n,0)} while the machine had only discovered three winning positions of \texttt{(1,1,0)}, \texttt{(2,2,0)}, and \texttt{(3,3,0)} (which are just specific examples of Anthony's solution).
					This could be one of multiple machines, as Nim-playing machines date back to 1940.
					The first was the Nimatron, which was first exhibited at the 1939-1940 World's Fair, and was later moved to Pittsburgh\footnote{Wikipedia: \url{https://en.wikipedia.org/wiki/Nimatron}}.
					The second was the Nimrod designed by John Makepeace Bennett and released on May 5, 1951.
					Turing was noted as playing this machine at the Festival of Britain during its initial run\cite{kk-britishgq}.
					The machine could be something else entirely, such as a list of instructions for a person to engage in verbatim so as to imitate a machine.
					This was not unheard of, as Turing was noted as creating and using a chess-playing set of instructions.
					Starchey did note himself as ``taking the part of the machine''.

					He uses this to get into his idea that the way a machine could "learn" would be through what is essentially abstraction.
					He indicates he has an idea of how this learning through abstraction might play out, specifically through the use of a teacher.

				\subsubsubsection{Page 3}
					Starchey lists three stages of learning from a teacher: exhibition (being shown examples), generalization (underlining the important commonalities), and verifying (checking for special/edge cases).
					He uses the example of differentiating powers of $x$: start with differentiations of $x$, $x^2$, and $x^3$, then extrapolate a rule for $x^n$ as a generalization\footnote{Usually $x^n \to n x^{n - 1}$, at least for me}, and finally check if it works for edge cases\footnote{Mine works for cases like $x^{\frac{1}{2}}$ or $x^{-1}$ but not cases like $x^0$ or $x^x$}.
					This largely mirrors how our own learning and testing happens, although we tend to go to a step 4 where we try to learn why it works, but that is neither here nor there.

					Starchey then comments that he believes it possible for the `Machester machine' to complete these stages, but admits that storage would be an issue.
					Turing seems to have acknowledged this in his initial radio broadcast\cite{amt-b-5}.
					Getting the machine to `programme itself from very simple and general input data' is a noted requirement.
					Starchey then notes the requirement of a suitable notation to communicate with and from the computer, which he assumes can be generated first for mathematics because of its simplicity in his mind.
					He then complains about writing mathematics on a typewriter\footnote{This was before \LaTeX}.

				\subsubsubsection{Page 4}
					Starchey proposes the idea of a machine that converts higher-level/math notation into machine code which is sent to the machine itself.
					This is similar to what does happen in a computer.

					He then talks about his attempt at a Draughts (checkers) playing program.

	\printbibliography
\end{document}